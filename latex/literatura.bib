@inproceedings{brants2007large,
  author    = {Thorsten Brants and Ashok C. Popat and Peng Xu and Franz J. Och and Jeffrey Dean},
  title     = {Large Language Models in Machine Translation},
  booktitle = {Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)},
  year      = {2007},
  pages     = {858--867},
  address   = {Prague, Czech Republic},
  publisher = {Association for Computational Linguistics}
}

@inproceedings{yong2023authors,
  author    = {Yong Zheng},
  title     = {Authors Info \& Claims},
  booktitle = {SIGITE '23: Proceedings of the 24th Annual Conference on Information Technology Education},
  month     = {October},
  year      = {2023},
  pages     = {66--72},
  doi       = {10.1145/3585059.3611431}
}
@inproceedings{baidoo2023education,
  author    = {D. BAİDOO-ANU and L. OWUSU ANSAH},
  title     = {Education in the Era of Generative Artificial Intelligence (AI): Understanding the Potential Benefits of ChatGPT in Promoting Teaching and Learning},
  journal   = {Journal of AI},
  volume    = {7},
  number    = {1},
  pages     = {52--62},
  year      = {2023},
  doi       = {10.61969/jai.1337500},
  url       = {https://doi.org/10.61969/jai.1337500}
}

@Article{info:doi/10.2196/50638,
author="Mesk{\'o}, Bertalan",
title="Prompt Engineering as an Important Emerging Skill for Medical Professionals: Tutorial",
journal="J Med Internet Res",
year="2023",
month="Oct",
day="4",
volume="25",
pages="e50638",
keywords="artificial intelligence; AI; digital health; future; technology; ChatGPT; GPT-4; large language models; language model; LLM; prompt; prompts; prompt engineering; AI tool; engineering; healthcare professional; decision-making; LLMs; chatbot; chatbots; conversational agent; conversational agents; NLP; natural language processing",
issn="1438-8871",
doi="10.2196/50638",
url="https://www.jmir.org/2023/1/e50638",
url="https://doi.org/10.2196/50638",
url="http://www.ncbi.nlm.nih.gov/pubmed/37792434"
}

@article{Chen2021EvaluatingLL,
  title={Evaluating Large Language Models Trained on Code},
  author={Mark Chen and Jerry Tworek and Heewoo Jun and Qiming Yuan and Henrique Ponde and Jared Kaplan and Harrison Edwards and Yura Burda and Nicholas Joseph and Greg Brockman and Alex Ray and Raul Puri and Gretchen Krueger and Michael Petrov and Heidy Khlaaf and Girish Sastry and Pamela Mishkin and Brooke Chan and Scott Gray and Nick Ryder and Mikhail Pavlov and Alethea Power and Lukasz Kaiser and Mohammad Bavarian and Clemens Winter and Philippe Tillet and Felipe Petroski Such and David W. Cummings and Matthias Plappert and Fotios Chantzis and Elizabeth Barnes and Ariel Herbert-Voss and William H. Guss and Alex Nichol and Igor Babuschkin and Suchir Balaji and Shantanu Jain and Andrew Carr and Jan Leike and Joshua Achiam and Vedant Misra and Evan Morikawa and Alec Radford and Matthew M. Knight and Miles Brundage and Mira Murati and Katie Mayer and Peter Welinder and Bob McGrew and Dario Amodei and Sam McCandlish and Ilya Sutskever and Wojciech Zaremba},
  journal={ArXiv},
  year={2021},
  volume={abs/2107.03374},
  url={https://api.semanticscholar.org/CorpusID:235755472}
}


@article{zhang2003machine,
  author    = {D. Zhang and J. J. Tsai},
  title     = {Machine Learning and Software Engineering},
  journal   = {Software Quality Journal},
  volume    = {11},
  number    = {2},
  pages     = {87--119},
  year      = {2003},
  month     = {Jun},
  doi       = {10.1023/A:1023760326768},
  url       = {https://doi.org/10.1023/A:1023760326768}
}

@INPROCEEDINGS{9833571,
  author={Pearce, Hammond and Ahmad, Baleegh and Tan, Benjamin and Dolan-Gavitt, Brendan and Karri, Ramesh},
  booktitle={2022 IEEE Symposium on Security and Privacy (SP)}, 
  title={Asleep at the Keyboard? Assessing the Security of GitHub Copilot’s Code Contributions}, 
  year={2022},
  volume={},
  number={},
  pages={754-768},
  keywords={Privacy;Codes;Computational modeling;Keyboards;Computer crime;Open source software;Software development management;Cybersecurity;Artificial Intelligence (AI);code generation;Common Weakness Enumerations (CWEs)},
  doi={10.1109/SP46214.2022.9833571}}


@Article{app13095783,
AUTHOR = {Rahman, Md. Mostafizer and Watanobe, Yutaka},
TITLE = {ChatGPT for Education and Research: Opportunities, Threats, and Strategies},
JOURNAL = {Applied Sciences},
VOLUME = {13},
YEAR = {2023},
NUMBER = {9},
ARTICLE-NUMBER = {5783},
URL = {https://www.mdpi.com/2076-3417/13/9/5783},
ISSN = {2076-3417},
ABSTRACT = {In recent years, the rise of advanced artificial intelligence technologies has had a profound impact on many fields, including education and research. One such technology is ChatGPT, a powerful large language model developed by OpenAI. This technology offers exciting opportunities for students and educators, including personalized feedback, increased accessibility, interactive conversations, lesson preparation, evaluation, and new ways to teach complex concepts. However, ChatGPT poses different threats to the traditional education and research system, including the possibility of cheating on online exams, human-like text generation, diminished critical thinking skills, and difficulties in evaluating information generated by ChatGPT. This study explores the potential opportunities and threats that ChatGPT poses to overall education from the perspective of students and educators. Furthermore, for programming learning, we explore how ChatGPT helps students improve their programming skills. To demonstrate this, we conducted different coding-related experiments with ChatGPT, including code generation from problem descriptions, pseudocode generation of algorithms from texts, and code correction. The generated codes are validated with an online judge system to evaluate their accuracy. In addition, we conducted several surveys with students and teachers to find out how ChatGPT supports programming learning and teaching. Finally, we present the survey results and analysis.},
DOI = {10.3390/app13095783}
}

@inproceedings{10.1145/3520312.3534862,
author = {Xu, Frank F. and Alon, Uri and Neubig, Graham and Hellendoorn, Vincent Josua},
title = {A systematic evaluation of large language models of code},
year = {2022},
isbn = {9781450392730},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3520312.3534862},
doi = {10.1145/3520312.3534862},
abstract = {Large language models (LMs) of code have recently shown tremendous promise in completing code and synthesizing code from natural language descriptions. However, the current state-of-the-art code LMs (e.g., Codex) are not publicly available, leaving many questions about their model and data design decisions. We aim to fill in some of these blanks through a systematic evaluation of the largest existing models: Codex, GPT-J, GPT-Neo, GPT-NeoX-20B, and CodeParrot, across various programming languages. Although Codex itself is not open-source, we find that existing opensource models do achieve close results in some programming languages, although targeted mainly for natural language
modeling. We further identify an important missing piece in the form of a large open-source model trained exclusively on a multi-lingual corpus of code. We release a new model, PolyCoder, with 2.7B parameters based on the GPT-2 architecture, that was trained on 249GB of code across 12 programming
languages on a single machine. In the C programming language, PolyCoder outperforms all models including Codex. Our trained models are open-source and publicly available at https://github.com/VHellendoorn/Code-LMs, which enables future research and application in this area.
We have an online appendix at https://arxiv.org/abs/2202.13169.},
booktitle = {Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming},
pages = {1–10},
numpages = {10},
keywords = {code generation, code language model, evaluation, open-source, pretraining},
location = {San Diego, CA, USA},
series = {MAPS 2022}
}

@article{MORADIDAKHEL2023111734,
title = {GitHub Copilot AI pair programmer: Asset or Liability?},
journal = {Journal of Systems and Software},
volume = {203},
pages = {111734},
year = {2023},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2023.111734},
url = {https://www.sciencedirect.com/science/article/pii/S0164121223001292},
author = {Arghavan {Moradi Dakhel} and Vahid Majdinasab and Amin Nikanjam and Foutse Khomh and Michel C. Desmarais and Zhen Ming (Jack) Jiang},
keywords = {Code completion, Language model, GitHub copilot, Testing},
abstract = {Automatic program synthesis is a long-lasting dream in software engineering. Recently, a promising Deep Learning (DL) based solution, called Copilot, has been proposed by OpenAI and Microsoft as an industrial product. Although some studies evaluate the correctness of Copilot solutions and report its issues, more empirical evaluations are necessary to understand how developers can benefit from it effectively. In this paper, we study the capabilities of Copilot in two different programming tasks: (i) generating (and reproducing) correct and efficient solutions for fundamental algorithmic problems, and (ii) comparing Copilot’s proposed solutions with those of human programmers on a set of programming tasks. For the former, we assess the performance and functionality of Copilot in solving selected fundamental problems in computer science, like sorting and implementing data structures. In the latter, a dataset of programming problems with human-provided solutions is used. The results show that Copilot is capable of providing solutions for almost all fundamental algorithmic problems, however, some solutions are buggy and non-reproducible. Moreover, Copilot has some difficulties in combining multiple methods to generate a solution. Comparing Copilot to humans, our results show that the correct ratio of humans’ solutions is greater than Copilot’s suggestions, while the buggy solutions generated by Copilot require less effort to be repaired. Based on our findings, if Copilot is used by expert developers in software projects, it can become an asset since its suggestions could be comparable to humans’ contributions in terms of quality. However, Copilot can become a liability if it is used by novice developers who may fail to filter its buggy or non-optimal solutions due to a lack of expertise.}
}

@article{yetistiren2023evaluating,
  title={Evaluating the Code Quality of AI-Assisted Code Generation Tools: An Empirical Study on GitHub Copilot, Amazon CodeWhisperer, and ChatGPT},
  author={Yetiştiren, Burak and others},
  journal={arXiv preprint arXiv:2304.10778},
  year={2023},
  url={https://doi.org/10.48550/arXiv.2304.10778}
}

@article{KASNECI2023102274,
title = {ChatGPT for good? On opportunities and challenges of large language models for education},
journal = {Learning and Individual Differences},
volume = {103},
pages = {102274},
year = {2023},
issn = {1041-6080},
doi = {https://doi.org/10.1016/j.lindif.2023.102274},
url = {https://www.sciencedirect.com/science/article/pii/S1041608023000195},
author = {Enkelejda Kasneci and Kathrin Sessler and Stefan Küchemann and Maria Bannert and Daryna Dementieva and Frank Fischer and Urs Gasser and Georg Groh and Stephan Günnemann and Eyke Hüllermeier and Stephan Krusche and Gitta Kutyniok and Tilman Michaeli and Claudia Nerdel and Jürgen Pfeffer and Oleksandra Poquet and Michael Sailer and Albrecht Schmidt and Tina Seidel and Matthias Stadler and Jochen Weller and Jochen Kuhn and Gjergji Kasneci},
keywords = {Large language models, Artificial intelligence, Education, Educational technologies},
abstract = {Large language models represent a significant advancement in the field of AI. The underlying technology is key to further innovations and, despite critical views and even bans within communities and regions, large language models are here to stay. This commentary presents the potential benefits and challenges of educational applications of large language models, from student and teacher perspectives. We briefly discuss the current state of large language models and their applications. We then highlight how these models can be used to create educational content, improve student engagement and interaction, and personalize learning experiences. With regard to challenges, we argue that large language models in education require teachers and learners to develop sets of competencies and literacies necessary to both understand the technology as well as their limitations and unexpected brittleness of such systems. In addition, a clear strategy within educational systems and a clear pedagogical approach with a strong focus on critical thinking and strategies for fact checking are required to integrate and take full advantage of large language models in learning settings and teaching curricula. Other challenges such as the potential bias in the output, the need for continuous human oversight, and the potential for misuse are not unique to the application of AI in education. But we believe that, if handled sensibly, these challenges can offer insights and opportunities in education scenarios to acquaint students early on with potential societal biases, criticalities, and risks of AI applications. We conclude with recommendations for how to address these challenges and ensure that such models are used in a responsible and ethical manner in education.}
}

@misc{vaswani2023attention,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2023},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={id='cs.CL' full_name='Computation and Language' is_active=True alt_name='cmp-lg' in_archive='cs' is_general=False description='Covers natural language processing. Roughly includes material in ACM Subject Class I.2.7. Note that work on artificial languages (programming languages, logics, formal systems) that does not explicitly address natural-language issues broadly construed (natural-language processing, computational linguistics, speech, text retrieval, etc.) is not appropriate for this area.'}
}

@article{rudolph2023war,
  title={War of the chatbots: Bard, Bing Chat, ChatGPT, Ernie and beyond. The new AI gold rush and its impact on higher education},
  author={Rudolph, J{\"u}rgen and Tan, Shannon and Tan, Samson},
  journal={Journal of Applied Learning and Teaching},
  volume={6},
  number={1},
  year={2023}
}

@inproceedings{NIPS2017_3f5ee243,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Attention is All you Need},
 url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
 volume = {30},
 year = {2017}
}

@misc{datacamp_attention_2024,
    title = {Attention Mechanism in Large Language Models: An Intuition},
    author = {DataCamp},
    year = {2024},
    url = {https://www.datacamp.com/blog/attention-mechanism-in-llms-intuition?dc_referrer=https%3A%2F%2Fwww.google.com%2F},
    note = {Accessed: 2024-06-13}
}


@misc{wang2024prompt,
      title={Prompt Engineering for Healthcare: Methodologies and Applications}, 
      author={Jiaqi Wang and Enze Shi and Sigang Yu and Zihao Wu and Chong Ma and Haixing Dai and Qiushi Yang and Yanqing Kang and Jinru Wu and Huawen Hu and Chenxi Yue and Haiyang Zhang and Yiheng Liu and Yi Pan and Zhengliang Liu and Lichao Sun and Xiang Li and Bao Ge and Xi Jiang and Dajiang Zhu and Yixuan Yuan and Dinggang Shen and Tianming Liu and Shu Zhang},
      year={2024},
      eprint={2304.14670},
      archivePrefix={arXiv},
      primaryClass={id='cs.AI' full_name='Artificial Intelligence' is_active=True alt_name=None in_archive='cs' is_general=False description='Covers all areas of AI except Vision, Robotics, Machine Learning, Multiagent Systems, and Computation and Language (Natural Language Processing), which have separate subject areas. In particular, includes Expert Systems, Theorem Proving (although this may overlap with Logic in Computer Science), Knowledge Representation, Planning, and Uncertainty in AI. Roughly includes material in ACM Subject Classes I.2.0, I.2.1, I.2.3, I.2.4, I.2.8, and I.2.11.'}
}

@misc{openai_codex,
    author       = {{OpenAI}},
    title        = {OpenAI Codex},
    year         = 2024,
    url          = {https://openai.com/index/openai-codex/},
    note         = {Accessed: 2024-06-17}
}

@misc{openai_chatgpt,
  author       = {OpenAI},
  title        = {ChatGPT},
  howpublished = {\url{https://openai.com/chatgpt/}},
  year         = 2024,
  note         = {Accessed: 2024-06-29}
}

@misc{saasworthy_codewhisperer,
  author       = {SaaSworthy},
  title        = {Amazon CodeWhisperer},
  howpublished = {\url{https://www.saasworthy.com/product/amazon-codewhisperer}},
  year         = 2024,
  note         = {Accessed: 2024-06-29}
}

@misc{github_copilot,
  author       = {GitHub},
  title        = {GitHub Copilot},
  howpublished = {\url{https://github.com/features/copilot/}},
  year         = 2024,
  note         = {Accessed: 2024-06-29}
}

@misc{github_copilot_chat,
  author       = {GitHub},
  title        = {GitHub Copilot Chat},
  howpublished = {\url{https://github.blog/2023-12-29-github-copilot-chat-now-generally-available-for-organizations-and-individuals//}},
  year         = 2023,
  note         = {Accessed: 2024-06-30}
}

@misc{Sundqvist1866649,
   author = {Sundqvist, Eric},
   institution = {Linnaeus University, Department of computer science and media technology (CM)},
   school = {Linnaeus University, Department of computer science and media technology (CM)},
   title = {AI-Assisted Unit Testing : Empirical Insights into GitHub Copilot Chat's Effectiveness and Collaborative Benefits},
  howpublished = {\url{https://www.diva-portal.org/smash/record.jsf?pid=diva2:1866649//}},
   year = 2024,
  note         = {Accessed: 2024-06-30}
}
